import sys, json, time, os
import pandas as pd
import numpy as np
import duckdb
import yfinance as yf
from datetime import datetime, timezone

DB = os.getenv("SP_DB_PATH","data/stock_signals.duckdb")


def normalize_prices(t, df):
    """
    yfinance가 MultiIndex([('Close','AAPL'), ...])로 주는 경우를
    단일 컬럼 DataFrame(Open, High, Low, Close, Adj Close, Volume)으로 정규화
    """
    import pandas as pd

    if df is None or df.empty:
        return df

    # MultiIndex -> 단일 레벨로 변환
    if isinstance(df.columns, pd.MultiIndex):
        # 티커 레벨을 찾아서 잘라내기
        levels = df.columns.names
        # 보통 (field, ticker) 순서. 맨 마지막 레벨이 티커인 케이스가 많음
        try:
            if t in df.columns.get_level_values(-1):
                df = df.xs(key=t, axis=1, level=-1)  # 마지막 레벨이 티커
            elif t in df.columns.get_level_values(0):
                df = df.xs(key=t, axis=1, level=0)   # 첫 레벨이 티커
            else:
                # 단일 티커만 존재하는 MultiIndex면 레벨만 제거
                df = df.droplevel(-1, axis=1)
        except Exception:
            # 실패 시 가능한 한 평탄화
            try:
                df.columns = [' '.join([str(x) for x in c if str(x)!='']).strip() for c in df.columns]
            except Exception:
                pass

    # 컬럼 이름 표준화
    rename_map = {}
    for c in list(df.columns):
        lc = str(c).strip().lower().replace("_"," ")
        if lc == "open":        rename_map[c] = "Open"
        elif lc == "high":      rename_map[c] = "High"
        elif lc == "low":       rename_map[c] = "Low"
        elif lc == "close":     rename_map[c] = "Close"
        elif lc in ("adj close","adjusted close"): rename_map[c] = "Adj Close"
        elif lc == "volume":    rename_map[c] = "Volume"
    df = df.rename(columns=rename_map)

    # 최소 컬럼만 남기고 숫자형으로
    for col in ("Open","High","Low","Close"):
        if col not in df.columns:
            return None
        df[col] = df[col].astype("float64")
    if "Volume" in df.columns:
        # yfinance는 종종 float로 오기도 함 → 일단 숫자로
        try:
            df["Volume"] = df["Volume"].astype("float64")
        except Exception:
            pass

    return df

DDL = """
CREATE TABLE IF NOT EXISTS runs(
  run_id VARCHAR PRIMARY KEY,
  ts_epoch BIGINT
);
CREATE TABLE IF NOT EXISTS signals(
  run_id  VARCHAR,
  ticker  VARCHAR,
  last_close DOUBLE,
  rsi14 DOUBLE,
  atr_pct DOUBLE,
  signal VARCHAR,
  crossed BOOLEAN,
  fast DOUBLE,
  slow DOUBLE,
  avg_vol20 DOUBLE
);
"""

def rsi(series, window=14):
    delta = series.diff()
    up = (delta.clip(lower=0)).ewm(alpha=1/window, adjust=False).mean()
    down = (-delta.clip(upper=0)).ewm(alpha=1/window, adjust=False).mean()
    rs = np.where(down==0, np.nan, up/down)
    return 100 - (100/(1+rs))

def atr_pct(df, window=14):
    h, l, c = df["High"], df["Low"], df["Close"]
    prev_c = c.shift(1)
    tr = pd.concat([
        (h - l).abs(),
        (h - prev_c).abs(),
        (l - prev_c).abs()
    ], axis=1).max(axis=1)
    atr = tr.ewm(alpha=1/window, adjust=False).mean()
    return (atr / c) * 100.0

def ma(series, w): return series.rolling(w, min_periods=w).mean()

def infer_signal(row):
    # 단순 룰 v1:
    # fast > slow & RSI 45~70 → BUY
    # fast < slow & RSI 30~55 → SELL
    # RSI >= 70 → TAKE_PROFIT
    # 그 외 WATCH
    if row["rsi14"] >= 70:
        return "TAKE_PROFIT"
    if row["fast"] > row["slow"] and 45 <= row["rsi14"] < 70:
        return "BUY"
    if row["fast"] < row["slow"] and 30 <= row["rsi14"] <= 55:
        return "SELL"
    return "WATCH"

def load_universe():
    con = duckdb.connect(DB, read_only=True)
    try:
        rows = con.execute("SELECT ticker FROM universe ORDER BY ticker").fetchall()
    finally:
        con.close()
    return [r[0] for r in rows]

def fetch_prices(tickers, period="1y"):
    # yfinance는 최대 200개까지 멀티 티커 권장 → 여기선 소수라 개별 호출
    data = {}
    for t in tickers:
        try:
            df = yf.download(t, period=period, interval="1d", progress=False, auto_adjust=False)
            df = normalize_prices(t, df)
            if df is None or df.empty:
                print(f"[signals] empty/invalid df after normalize: {t}")
                continue
            data[t] = df
        except Exception as e:
            print(f"[signals] fetch error {t}: {e}")
            continue
    return data

def compute_one(t, df, rsi_w=14, atr_w=14, ma_fast=20, ma_slow=60):
    """
    티커 t의 시세 df(DataFrame: yfinance download 결과)로
    RSI/ATR/MA를 계산해 단일 레코드(dict) 반환.
    반환값이 None이면 데이터가 부족하거나 지표 계산 실패.
    """
    # 필수 컬럼/길이 점검
    if df is None or df.empty:
        return None
    need = {"High", "Low", "Close"}
    if not need.issubset(set(df.columns)):
        return None
    min_rows = max(rsi_w, atr_w, ma_slow)
    if len(df) < min_rows:
        return None

    # float 변환 및 지표 계산
    out = pd.DataFrame(index=df.index)
    out["Close"] = df["Close"].astype(float)
    out["High"]  = df["High"].astype(float)
    out["Low"]   = df["Low"].astype(float)

    out["rsi14"]   = rsi(out["Close"], rsi_w)
    out["atr_pct"] = atr_pct(out, atr_w)
    out["fast"]    = ma(out["Close"], ma_fast)
    out["slow"]    = ma(out["Close"], ma_slow)
    out["crossed"] = (out["fast"] > out["slow"])

    # 유효한 최신 행 선택
    out = out.dropna(subset=["rsi14", "atr_pct", "fast", "slow", "Close"])
    if out.empty:
        return None
    last = out.iloc[-1]

    # 신호 산출
    sig = infer_signal(last)

    # 거래량 20일 평균(있을 때만)
    avg_vol20_val = None
    if "Volume" in df.columns:
        vol20_last = df["Volume"].rolling(20, min_periods=1).mean().iloc[-1]
        if pd.notna(vol20_last):
            avg_vol20_val = float(vol20_last)

    return {
        "ticker": t,
        "last_close": float(last["Close"]),
        "rsi14": float(last["rsi14"]),
        "atr_pct": float(last["atr_pct"]),
        "signal": sig,
        "crossed": bool(last["crossed"]),
        "fast": float(last["fast"]),
        "slow": float(last["slow"]),
        "avg_vol20": avg_vol20_val
    }

def persist(run_id, rows):
    con = duckdb.connect(DB)
    try:
        con.execute(DDL)
        con.execute("INSERT OR REPLACE INTO runs(run_id, ts_epoch) VALUES (?,?)", [run_id, int(time.time())])
        if rows:
            df = pd.DataFrame(rows)
            con.execute("DELETE FROM signals WHERE run_id = ?", [run_id])
            con.execute("CREATE TABLE IF NOT EXISTS signals AS SELECT * FROM df LIMIT 0")  # ensure schema
            con.execute("INSERT INTO signals SELECT * FROM df")
    finally:
        con.close()

def run(action, payload):
    if action != "run.batch":
        return {"ok": False, "error": "unknown action"}
    source = payload.get("source","universe")
    rsi_w   = int(payload.get("rsi_window",14))
    atr_w   = int(payload.get("atr_window",14))
    mfast   = int(payload.get("ma_fast",20))
    mslow   = int(payload.get("ma_slow",60))
    limit   = int(payload.get("limit",500))

    tickers = []
    if source == "csv" and payload.get("csv_path"):
        df = pd.read_csv(payload["csv_path"])
        tickers = [str(t).strip() for t in df["ticker"].dropna().tolist()][:limit]
    else:
        tickers = load_universe()[:limit]

    prices = fetch_prices(tickers)
    rows = []
    for t, df in prices.items():
        rec = compute_one(t, df, rsi_w, atr_w, mfast, mslow)
        if rec: rows.append(rec)

    run_id = f"run_{int(time.time())}"
    persist(run_id, rows)

    return {"ok": True, "run_id": run_id, "signals": rows}

if __name__=="__main__":
    action = sys.argv[1]
    payload = json.loads(sys.argv[2]) if len(sys.argv)>2 else {}
    print(json.dumps(run(action,payload), ensure_ascii=False))
